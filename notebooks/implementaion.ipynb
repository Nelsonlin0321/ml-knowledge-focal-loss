{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/facebookresearch/fvcore/blob/main/fvcore/nn/focal_loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "class_num = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.randn(batch_size,class_num)\n",
    "inputs = torch.tensor(inputs,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9175, -1.3873, -0.1195,  ...,  2.2159,  0.8280, -0.5806],\n",
       "        [-0.3103, -0.5549, -0.7568,  ...,  0.7188, -1.1780, -1.0346],\n",
       "        [-2.5204,  0.1631, -1.3644,  ...,  0.7163,  1.5505,  1.0744],\n",
       "        ...,\n",
       "        [-1.3316,  0.0582,  1.5016,  ..., -0.4068,  1.8959,  0.0139],\n",
       "        [-0.0294, -0.6537, -0.1888,  ..., -0.0366, -0.7971, -1.3894],\n",
       "        [ 0.0738, -0.5909, -0.9811,  ..., -0.1257, -0.5891, -2.3516]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [np.random.randint(0,128) for _ in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.zeros(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bid in range(batch_size):\n",
    "    targets[bid][labels[bid]] =1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor(targets,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1371, 0.2229, 0.6352,  ..., 2.3194, 1.1905, 0.4444],\n",
       "        [0.5500, 0.4537, 0.3847,  ..., 1.1158, 0.2684, 0.3041],\n",
       "        [0.0774, 0.7780, 0.2276,  ..., 1.1141, 1.7429, 1.3682],\n",
       "        ...,\n",
       "        [0.2343, 0.7227, 1.7027,  ..., 0.5103, 2.0358, 0.7001],\n",
       "        [0.6786, 0.4188, 0.6032,  ..., 0.6750, 0.3720, 1.6119],\n",
       "        [0.7307, 0.4407, 0.3184,  ..., 0.6323, 0.4414, 0.0909]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# echo cross binary loss for each class\n",
    "ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probality to be true\n",
    "probalities = torch.sigmoid(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1281, 0.1998, 0.4702,  ..., 0.9017, 0.6959, 0.3588],\n",
       "        [0.4230, 0.3647, 0.3193,  ..., 0.6723, 0.2354, 0.2622],\n",
       "        [0.0744, 0.5407, 0.2035,  ..., 0.6718, 0.8250, 0.7454],\n",
       "        ...,\n",
       "        [0.2089, 0.5145, 0.8178,  ..., 0.3997, 0.8694, 0.5035],\n",
       "        [0.4927, 0.3422, 0.4529,  ..., 0.4909, 0.3106, 0.1995],\n",
       "        [0.5184, 0.3564, 0.2727,  ..., 0.4686, 0.3568, 0.0869]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probablities to be correct\n",
    "probalities_correct = probalities * targets + (1 - probalities) * (1 - targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./../focal_loss.png\" width=500 height=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ce_loss * ((1 - probalities_correct) ** gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1281, 0.1998, 0.4702,  ..., 0.9017, 0.6959, 0.3588],\n",
       "        [0.4230, 0.3647, 0.3193,  ..., 0.6723, 0.2354, 0.2622],\n",
       "        [0.0744, 0.5407, 0.2035,  ..., 0.6718, 0.8250, 0.7454],\n",
       "        ...,\n",
       "        [0.2089, 0.5145, 0.8178,  ..., 0.3997, 0.8694, 0.5035],\n",
       "        [0.4927, 0.3422, 0.4529,  ..., 0.4909, 0.3106, 0.1995],\n",
       "        [0.5184, 0.3564, 0.2727,  ..., 0.4686, 0.3568, 0.0869]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1371, 0.2229, 0.6352,  ..., 2.3194, 1.1905, 0.4444],\n",
       "        [0.5500, 0.4537, 0.3847,  ..., 1.1158, 0.2684, 0.3041],\n",
       "        [0.0774, 0.7780, 0.2276,  ..., 1.1141, 1.7429, 1.3682],\n",
       "        ...,\n",
       "        [0.2343, 0.7227, 1.7027,  ..., 0.5103, 2.0358, 0.7001],\n",
       "        [0.6786, 0.4188, 0.6032,  ..., 0.6750, 0.3720, 1.6119],\n",
       "        [0.7307, 0.4407, 0.3184,  ..., 0.6323, 0.4414, 0.0909]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8169)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2517e-03, 8.9038e-03, 1.4042e-01,  ..., 1.8857e+00, 5.7659e-01,\n",
       "         5.7210e-02],\n",
       "        [9.8429e-02, 6.0354e-02, 3.9232e-02,  ..., 5.0440e-01, 1.4876e-02,\n",
       "         2.0903e-02],\n",
       "        [4.2868e-04, 2.2743e-01, 9.4257e-03,  ..., 5.0282e-01, 1.1862e+00,\n",
       "         7.6028e-01],\n",
       "        ...,\n",
       "        [1.0225e-02, 1.9133e-01, 1.1388e+00,  ..., 8.1509e-02, 1.5388e+00,\n",
       "         1.7748e-01],\n",
       "        [1.6470e-01, 4.9026e-02, 1.2374e-01,  ..., 1.6264e-01, 3.5896e-02,\n",
       "         1.0329e+00],\n",
       "        [1.9639e-01, 5.5984e-02, 2.3669e-02,  ..., 1.3884e-01, 5.6204e-02,\n",
       "         6.8737e-04]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3583)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_focal_loss(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    alpha: float = -1,\n",
    "    gamma: float = 2,\n",
    "    reduction: str = \"none\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "    Args:\n",
    "        inputs: A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
    "                 classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha: (optional) Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples. Default = -1 (no weighting).\n",
    "        gamma: Exponent of the modulating factor (1 - p_t) to\n",
    "               balance easy vs hard examples.\n",
    "        reduction: 'none' | 'mean' | 'sum'\n",
    "                 'none': No reduction will be applied to the output.\n",
    "                 'mean': The output will be averaged.\n",
    "                 'sum': The output will be summed.\n",
    "    Returns:\n",
    "        Loss tensor with the reduction option applied.\n",
    "    \"\"\"\n",
    "    inputs = inputs.float()\n",
    "    targets = targets.float()\n",
    "    p = torch.sigmoid(inputs)\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = p * targets + (1 - p) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    if reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "\n",
    "    return loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eb94250e807a4b8afb9c3a175190453ecbfb9c88221c7c39a57fa462e93c843"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
